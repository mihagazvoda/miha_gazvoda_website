---
title: "Fooled by correlation"
description: |
  A short description of the post.
author:
  - name: Miha Gazvoda
    url: https://mihagazvoda.com
date: 05-29-2021
output:
  distill::distill_article:
    self_contained: false
---

Once upon a time I worked as a student data scientist for a start-up where we wanted to predict something about the person based on the measurement we did on them. In theory, these measurements (biomarkers) should correlate with the thing we wanted to predict but: 

> In theory, theory and practice are the same. In practice, they are not. - Unknown

So we had more than 10 features per person and only about, let's say 30 persons. We often found correlations but then got dissapointed after additional measurements when it dissapeared. It was like a cat chasing its tail. I got to wonder, ok, strongly suspect, that we are getting correlations out of thin air. My plan was to do a simulation to check how probable is to get correlations as they were ours. I left the job before I got to do the simulation.

Until, a few days ago I came across the video by Nassim Nicholas Taleb, doing and explain exactly the thing I planned to do. You can watch it on [Youtube](https://www.youtube.com/watch?v=fb921ZrM6h0). 

## How to fool yourself with correlation 101

Let's simulate the situation we were probably in. Let's say we measured 25 subjects and then calculated 15 features for each one. Each one of the features (including the outcome) is random^[Normally distributed with the mean 0 and standard deviation 1.].

```{r}
library(dplyr)
library(tidyr)
library(ggplot2)

n_features <- 15
n_subjects <- 25

subject_data <- as_tibble(
  replicate(n_features + 1, rnorm(n_subjects)), 
  .name_repair = ~c(paste0("x", as.character(1:n_features)), "y")
)

corrs_with_y <- subject_data %>% 
  corrr::correlate(method = "pearson") %>%
  corrr::focus(y) %>% 
  rename(feature = "term", r = "y") %>% 
  arrange(desc(abs(r)))

corrr::fashion(corrs_with_y)
```

We are getting quite decent correlations (at least that's what I thought) out of the thin air! Look at the plots below, displaying 3 best (spurrious) correlations. We often see something like this in the news, even scientific publications! As Taleb said: 

> The point is not that the correlation is not causation, is that very often correlation is not correlation.


```{r}
specify_decimal <- function(x, k) trimws(format(round(x, k), nsmall=k))

features_with_highest_corrs <- corrs_with_y %>% 
  head(3)

subject_data %>%
  pivot_longer(cols = starts_with("x"), names_to = "feature", values_to = "x") %>% 
  right_join(features_with_highest_corrs, by = "feature") %>% 
  mutate(label = paste0(feature, ": ", specify_decimal(r, 2))) %>% 
  ggplot(aes(x, y)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  facet_grid(~forcats::fct_reorder(label, desc(abs(r)))) + 
  theme_classic()
```

How often can totally random data produce "high" correlations, let's say 0.3 or higher (in absolute terms)? It depends on a sample size. Let's simulate!

```{r}
simulated_r <- replicate(10000, cor(rnorm(n_subjects), rnorm(n_subjects)))

tibble(r = simulated_r) %>% 
  ggplot(aes(r)) +
  geom_histogram(aes(y = ..density..)) +
  stat_function(fun = dnorm, args = list(mean = mean(simulated_r), sd = sd(simulated_r)))
```

This looks like the most normal function I've seen. Let's check how tweaking/gaming the metrics can be seen. 


```{r}
df <- crossing(
  n = seq(5, 100, 5),
  k = 1:1000
) %>% 
  rowwise() %>% 
  mutate(r = cor(rnorm(n), rnorm(n))) 

# %>% 
#   # group_by(n) %>% 
#   # summarise(sd_r = sd(r)) %>% 
#   ggplot(aes(n , r, group = n)) +
#   geom_violin()
```

```{r}
df %>% 
  filter(n == n_subjects) %>% 
  ggplot(aes(r)) +
  geom_histogram()
```


```{r}
df %>% 
  group_by(n) %>% 
  summarise(
    sd = sd(r), 
    p90 = quantile(abs(r), 0.9)
  ) %>% 
  ggplot(aes(x = n)) + 
  geom_line(aes(y = sd)) + 
  geom_line(aes(y = p90), linetype = "dashed")
```


```{r}
df <- tidyr::crossing(
  n = c(5, 10, 20, 30, 50, 100, 1000),
  r_actual = seq(0, 0.95, by = 0.05),
  k = 1:10 # TODO should be 1000
) %>% 
  rowwise() %>% 
  mutate(
    x = list(rnorm(n)),
    y = list(faux::rnorm_pre(x, r = r_actual)),
    r_calc = cor(x, y)
  )
```

```{r}
df %>% 
    filter(r_actual == 0.9, n == 5) %>% 
    ggplot(aes(r_calc)) + 
    geom_histogram(binwidth = 0.1)
```

```{r}
tmp <- df %>% 
  group_by(n, r_actual, r_calc_rounded = plyr::round_any(r_calc, 0.1)) %>% 
  summarise(count = n()) %>% 
  mutate(p = count / sum(count)) %>% 
  ungroup() %>% 
  bind_rows(
      filter(., r_actual != 0) %>% 
      mutate(across(c(r_actual, r_calc_rounded), `-`))
  )
```

```{r}
tmp2 <- tmp %>% 
  group_by(n, r_calc_rounded) %>% 
  mutate(p_posterior = p / sum(p))
```

```{r}
tmp2 %>% 
  filter(r_calc_rounded == 0.2, n == 20) %>% 
  ggplot(aes(r_actual, p_posterior)) + 
  geom_line()
```



TODO exaplin gaming metrics: for example choosing best 3 correlations out of 20

mention that this also holds for other metrics, not only correlation

the lesson is: 1. metrics are random variables. If they are random variables, they will be gamed. 
