---
title: "Fooled by correlation"
description: |
  How to not get fooled by correlation using Bayesian stats
author:
  - name: Miha Gazvoda
    url: https://mihagazvoda.com
date: 08-15-2021
output:
  distill::distill_article:
    self_contained: false
---

```{r}
library(lemon)
knit_print.data.frame <- lemon_print
knit_print.table <- lemon_print
knit_print.grouped_df <- lemon_print 
knit_print.tibble <- lemon_print
knit_print.tbl <- lemon_print
options(digits=2)
ggplot2::theme_set(ggplot2::theme_classic())

knitr::opts_chunk$set(cache = TRUE)
```


Once upon a time I worked as a student data scientist for a start-up where we wanted to predict a person's bio-marker based on the measurement we did on them. In theory, these measurements (biomarkers) should correlate with the thing we wanted to predict but: 

> In theory, theory and practice are the same. In practice, they are not. - Unknown

So we had more than 10 features per person and only about, let's say 30 persons. We often found correlations but then got disappointed after additional measurements when the correlation dissapeared. It was like a cat chasing its tail. I got to suspect, that we were getting correlations out of a thin air. My plan was to do a simulation to check how probable is to get correlations as they were ours by chance. I left the job before I got to do the simulation.

Until, a few days ago I came across the video by Nassim Nicholas Taleb, doing and explain exactly the thing I planned to do. You can watch it on [Youtube](https://wwwyoutube.com/watch?v=fb921ZrM6h0). 

## How to fool yourself with correlation 101

Let's simulate the situation we were probably in. Let's say we measured 25 subjects and then calculated 15 features for each one. Each one of the features, including the outcome, is random^[Normally distributed with the mean 0 and standard deviation 1.] and independent from others.

```{r}
library(dplyr)
library(tidyr)
library(ggplot2)

n_features <- 15
n_subjects <- 25

subject_data <- as_tibble(
  replicate(n_features + 1, rnorm(n_subjects)), 
  .name_repair = ~c(paste0("x", as.character(1:n_features)), "y")
)

subject_data %>% 
  select(x1, x2, x3, x4, x5, y) %>% 
  head()
```

As you can see above, each row presents one subject. Columns `x1` to `x15` (only the first 5 is displayed) present features and `y` a value we want to predict. Let's calculate correlation correlation of each future in respect to `y`. In reality, they should be zero, but are they? 

```{r}
corrs_with_y <- subject_data %>% 
  corrr::correlate(method = "pearson") %>%
  corrr::focus(y) %>% 
  rename(feature = "term", r = "y") %>% 
  arrange(desc(abs(r)))

corrr::fashion(corrs_with_y)
```

We are getting quite decent (at least that's what I thought) correlations out of the thin air! Look at the plots below, displaying 3 best spurious correlations. We often see something like this in the news, even scientific publications! As Taleb says: 

> The point is not that the correlation is not causation, is that very often correlation is not correlation.


```{r, echo=FALSE}
specify_decimal <- function(x, k) trimws(format(round(x, k), nsmall=k))

features_with_highest_corrs <- corrs_with_y %>% 
  head(3)

subject_data %>%
  pivot_longer(cols = starts_with("x"), names_to = "feature", values_to = "x") %>%
  right_join(features_with_highest_corrs, by = "feature") %>% 
  mutate(label = paste0(feature, ": ", specify_decimal(r, 2))) %>% 
  ggplot(aes(x, y)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  facet_grid(~forcats::fct_reorder(label, desc(abs(r))))
```

TODO exaplin gaming metrics: for example choosing best 3 correlations out of 20

## Simulation: Getting spurious correlations

How often can totally random data produce "high" correlations. Let's look at the distribution of correlations of two independent datasets with `n_subjects` data points.

```{r}
simulated_correlations <- replicate(10000, cor(rnorm(n_subjects), rnorm(n_subjects)))

tibble(r = simulated_correlations) %>% 
  ggplot(aes(r)) +
  geom_histogram(aes(y = ..density..)) +
  stat_function(
    fun = dnorm, 
    args = list(mean = mean(simulated_correlations), sd = sd(simulated_correlations))
  )
```

This looks like the most normal function I've seen. See the table below what's the probability to get higher than something correlation.

```{r}
tibble(
  simulated_correlations = list(simulated_correlations), 
  r_threshold = seq(0.1, 0.5, by = 0.1)
) %>%
  rowwise() %>% 
  mutate(p_above_threshold = mean(abs(simulated_correlations) > r_threshold)) %>% 
  ungroup() %>% 
  select(r_threshold, p_above_threshold)
```

That's not little! Remember the time when you were all enthusiastic about 0.3 correlation in your data. Below let's see how standard deviation and 95th percentile change with sample size.

```{r}
df <- crossing(
  n = seq(5, 100, 5),
  k = 1:1000
) %>% 
  rowwise() %>% 
  mutate(r = cor(rnorm(n), rnorm(n))) 

df %>% 
  group_by(n) %>% 
  summarise(
    sd = sd(r), 
    p90 = quantile(abs(r), 0.95)
  ) %>% 
  ggplot(aes(x = n)) + 
  geom_line(aes(y = sd)) + 
  geom_line(aes(y = p90), linetype = "dashed") + 
  expand_limits(y = 0)
```

The values are dropping as $sqrt(n)$. 

The funny thing is, since now you know mean and standard deviation describing distribution of pearson correlation coefficients you can actually hypotesize test it. You can calculate `p` value, telling you probability that such `r` could be generated if there's no correlation and then reject the null hypothesis that it comes from distribution where actual r = 0 if p < 0.05. 

But this might not be the answer we are looking for. What if we are looking for `P(r > some value|observed r)`? Then, my friend, we have to turn to our friend Bayes.

## Bayesian party

Right now, we were calculating likelihood distribution of $P( r_{obs} | r_{true})$. But we interested in posterior $P( r_{true} | r_{obs})$ - what's the distribution of actual $r$ given you observed `r=0.5`, for example?

```{r}
correlations_positive_only <- tidyr::crossing(
  n = as.integer(c(10, 50, 100, 1000)),
  r_true = seq(0, 0.95, by = 0.05),
  k = 1:1000 # TODO should be 1000
) %>% 
  rowwise() %>% 
  mutate(
    x = list(rnorm(n)),
    y = list(faux::rnorm_pre(x, r = r_true)),
    r_obs = cor(x, y)
  ) %>% 
  select(-x, -y)

df <- bind_rows(
    correlations_positive_only,
    correlations_positive_only %>% 
      filter(r_true > 0) %>%
      mutate(across(c(r_true, r_obs), `-`))
  )

df
```

This is how we can get likelihood distribution, the same as we had above for $r_{true}=0$. Now let's do it for different parameters. 

```{r}
df %>% 
    filter(r_true == 0.5, n == 100) %>% 
    ggplot(aes(r_obs)) + 
    geom_density()
```

Let's go to Bayesian formula again. $$P(r_{true} | r_{obs}) = P(r_{true}) P( r_{obs} | r_{true})$$. As usual, we will drop the bottom part. First for each $n$ and $r_{true}$ what's the probability it will generate $r_{obs}$. We bin $r_{obs}$ so we can actually calculate probabilities for it. This technique is called grid approximation - you can read more about it on my [Intuitive Bayesian Inference](https://mihagazvoda.com/posts/2020-11-24-bayesian-updating/) blog post. 

```{r}
tmp <- df %>% 
  group_by(n, r_true, r_obs_rounded = plyr::round_any(r_obs, 0.1)) %>% 
  summarise(count = n()) %>% 
  mutate(likelihood = count / sum(count)) %>% 
  ungroup() %>% 
  mutate(
    prior = dnorm(r_true, x = 0, sd = 0.5),
    posterior_unstd = likelihood * prior
  ) %>% 
  group_by(n, r_obs_rounded) %>% 
  mutate(posterior = posterior_unstd / sum(posterior_unstd))

tmp
```



```{r}
tmp %>% 
  filter(as.character(r_obs_rounded) %in% as.character(c(0.3, 0.5, 0.7))) %>% 
  ggplot(aes(r_true, posterior, color = factor(n))) + 
  geom_line() +
  facet_wrap(~r_obs_rounded, ncol = 1)
```





mention that this also holds for other metrics, not only correlation

the lesson is: 1. metrics are random variables. If they are random variables, they will be gamed. 
